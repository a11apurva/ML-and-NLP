{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## word2vec model creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s',\\\n",
    "    level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_features = 300    # Word vector dimensionality                      \n",
    "min_word_count = 10   # Minimum word count                        \n",
    "num_workers = 4       # Number of threads to run in parallel\n",
    "context = 10          # Context window size                                                                                    \n",
    "downsampling = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentences=[]\n",
    "for line in open(\"corpus_word2vec.txt\"):\n",
    "    line=line.strip()\n",
    "    line=line.split()\n",
    "    sentences.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-06-07 14:38:45,614 : INFO : collecting all words and their counts\n",
      "2018-06-07 14:38:45,622 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-06-07 14:38:47,253 : INFO : PROGRESS: at sentence #10000, processed 3969558 words, keeping 57778 word types\n",
      "2018-06-07 14:38:47,649 : INFO : collected 62152 word types from a corpus of 4556199 raw words and 11505 sentences\n",
      "2018-06-07 14:38:47,657 : INFO : Loading a fresh vocabulary\n",
      "2018-06-07 14:38:47,910 : INFO : min_count=10 retains 14044 unique words (22% of original 62152, drops 48108)\n",
      "2018-06-07 14:38:47,913 : INFO : min_count=10 leaves 4445316 word corpus (97% of original 4556199, drops 110883)\n",
      "2018-06-07 14:38:48,131 : INFO : deleting the raw counts dictionary of 62152 items\n",
      "2018-06-07 14:38:48,147 : INFO : sample=0.001 downsamples 37 most-common words\n",
      "2018-06-07 14:38:48,147 : INFO : downsampling leaves estimated 4161363 word corpus (93.6% of prior 4445316)\n",
      "2018-06-07 14:38:48,162 : INFO : estimated required memory for 14044 words and 300 dimensions: 40727600 bytes\n",
      "2018-06-07 14:38:48,457 : INFO : resetting layer weights\n",
      "2018-06-07 14:38:48,981 : INFO : training model with 4 workers on 14044 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=10\n",
      "2018-06-07 14:38:50,005 : INFO : PROGRESS: at 1.46% examples, 236772 words/s, in_qsize 8, out_qsize 0\n",
      "2018-06-07 14:38:51,010 : INFO : PROGRESS: at 2.48% examples, 248575 words/s, in_qsize 8, out_qsize 0\n",
      "2018-06-07 14:38:52,038 : INFO : PROGRESS: at 3.62% examples, 241637 words/s, in_qsize 7, out_qsize 0\n",
      "2018-06-07 14:38:53,053 : INFO : PROGRESS: at 4.59% examples, 236504 words/s, in_qsize 7, out_qsize 0\n",
      "2018-06-07 14:38:54,056 : INFO : PROGRESS: at 5.71% examples, 232972 words/s, in_qsize 7, out_qsize 0\n",
      "2018-06-07 14:38:55,133 : INFO : PROGRESS: at 6.68% examples, 238161 words/s, in_qsize 7, out_qsize 0\n",
      "2018-06-07 14:38:56,205 : INFO : PROGRESS: at 8.01% examples, 242299 words/s, in_qsize 7, out_qsize 0\n",
      "2018-06-07 14:38:57,219 : INFO : PROGRESS: at 9.48% examples, 244433 words/s, in_qsize 7, out_qsize 0\n",
      "2018-06-07 14:38:58,230 : INFO : PROGRESS: at 10.71% examples, 245700 words/s, in_qsize 8, out_qsize 0\n",
      "2018-06-07 14:38:59,296 : INFO : PROGRESS: at 11.83% examples, 246785 words/s, in_qsize 8, out_qsize 0\n",
      "2018-06-07 14:39:00,324 : INFO : PROGRESS: at 13.33% examples, 248391 words/s, in_qsize 8, out_qsize 0\n",
      "2018-06-07 14:39:01,369 : INFO : PROGRESS: at 14.75% examples, 249519 words/s, in_qsize 8, out_qsize 0\n",
      "2018-06-07 14:39:02,421 : INFO : PROGRESS: at 16.00% examples, 250550 words/s, in_qsize 8, out_qsize 0\n",
      "2018-06-07 14:39:03,444 : INFO : PROGRESS: at 17.46% examples, 251700 words/s, in_qsize 7, out_qsize 0\n",
      "2018-06-07 14:39:04,539 : INFO : PROGRESS: at 18.64% examples, 251494 words/s, in_qsize 8, out_qsize 0\n",
      "2018-06-07 14:39:05,594 : INFO : PROGRESS: at 19.73% examples, 248182 words/s, in_qsize 7, out_qsize 0\n",
      "2018-06-07 14:39:06,609 : INFO : PROGRESS: at 20.84% examples, 242972 words/s, in_qsize 5, out_qsize 2\n",
      "2018-06-07 14:39:07,641 : INFO : PROGRESS: at 22.05% examples, 243225 words/s, in_qsize 8, out_qsize 0\n",
      "2018-06-07 14:39:08,696 : INFO : PROGRESS: at 22.57% examples, 237634 words/s, in_qsize 8, out_qsize 0\n",
      "2018-06-07 14:39:09,710 : INFO : PROGRESS: at 23.67% examples, 236787 words/s, in_qsize 7, out_qsize 0\n",
      "2018-06-07 14:39:10,729 : INFO : PROGRESS: at 24.72% examples, 237437 words/s, in_qsize 8, out_qsize 0\n",
      "2018-06-07 14:39:11,775 : INFO : PROGRESS: at 26.03% examples, 238270 words/s, in_qsize 8, out_qsize 0\n",
      "2018-06-07 14:39:12,801 : INFO : PROGRESS: at 26.96% examples, 239274 words/s, in_qsize 8, out_qsize 0\n",
      "2018-06-07 14:39:13,808 : INFO : PROGRESS: at 28.37% examples, 240242 words/s, in_qsize 7, out_qsize 0\n",
      "2018-06-07 14:39:14,811 : INFO : PROGRESS: at 29.76% examples, 240789 words/s, in_qsize 7, out_qsize 0\n",
      "2018-06-07 14:39:15,819 : INFO : PROGRESS: at 30.98% examples, 242000 words/s, in_qsize 8, out_qsize 0\n",
      "2018-06-07 14:39:16,819 : INFO : PROGRESS: at 31.97% examples, 241618 words/s, in_qsize 7, out_qsize 0\n",
      "2018-06-07 14:39:17,883 : INFO : PROGRESS: at 33.47% examples, 242501 words/s, in_qsize 7, out_qsize 0\n",
      "2018-06-07 14:39:18,898 : INFO : PROGRESS: at 34.75% examples, 242435 words/s, in_qsize 7, out_qsize 0\n",
      "2018-06-07 14:39:19,945 : INFO : PROGRESS: at 36.00% examples, 243196 words/s, in_qsize 8, out_qsize 0\n",
      "2018-06-07 14:39:20,958 : INFO : PROGRESS: at 37.34% examples, 243539 words/s, in_qsize 7, out_qsize 0\n",
      "2018-06-07 14:39:21,961 : INFO : PROGRESS: at 38.61% examples, 244561 words/s, in_qsize 7, out_qsize 0\n",
      "2018-06-07 14:39:23,001 : INFO : PROGRESS: at 39.68% examples, 243524 words/s, in_qsize 8, out_qsize 0\n",
      "2018-06-07 14:39:24,060 : INFO : PROGRESS: at 41.36% examples, 243538 words/s, in_qsize 7, out_qsize 0\n",
      "2018-06-07 14:39:25,083 : INFO : PROGRESS: at 42.48% examples, 244551 words/s, in_qsize 8, out_qsize 0\n",
      "2018-06-07 14:39:26,092 : INFO : PROGRESS: at 43.84% examples, 245534 words/s, in_qsize 7, out_qsize 0\n",
      "2018-06-07 14:39:27,204 : INFO : PROGRESS: at 44.93% examples, 245555 words/s, in_qsize 6, out_qsize 1\n",
      "2018-06-07 14:39:28,248 : INFO : PROGRESS: at 46.12% examples, 244758 words/s, in_qsize 8, out_qsize 0\n",
      "2018-06-07 14:39:29,253 : INFO : PROGRESS: at 47.02% examples, 245321 words/s, in_qsize 7, out_qsize 0\n",
      "2018-06-07 14:39:30,315 : INFO : PROGRESS: at 48.37% examples, 244989 words/s, in_qsize 6, out_qsize 1\n",
      "2018-06-07 14:39:31,343 : INFO : PROGRESS: at 49.80% examples, 245278 words/s, in_qsize 8, out_qsize 0\n",
      "2018-06-07 14:39:32,378 : INFO : PROGRESS: at 51.02% examples, 245768 words/s, in_qsize 7, out_qsize 0\n",
      "2018-06-07 14:39:33,407 : INFO : PROGRESS: at 52.31% examples, 246473 words/s, in_qsize 7, out_qsize 0\n",
      "2018-06-07 14:39:34,418 : INFO : PROGRESS: at 53.47% examples, 245853 words/s, in_qsize 8, out_qsize 0\n",
      "2018-06-07 14:39:35,434 : INFO : PROGRESS: at 54.40% examples, 244059 words/s, in_qsize 7, out_qsize 0\n",
      "2018-06-07 14:39:36,488 : INFO : PROGRESS: at 55.17% examples, 242629 words/s, in_qsize 8, out_qsize 0\n",
      "2018-06-07 14:39:37,530 : INFO : PROGRESS: at 56.16% examples, 241543 words/s, in_qsize 7, out_qsize 0\n",
      "2018-06-07 14:39:38,605 : INFO : PROGRESS: at 57.22% examples, 240410 words/s, in_qsize 7, out_qsize 0\n",
      "2018-06-07 14:39:39,649 : INFO : PROGRESS: at 58.15% examples, 239095 words/s, in_qsize 7, out_qsize 0\n",
      "2018-06-07 14:39:40,668 : INFO : PROGRESS: at 59.09% examples, 239128 words/s, in_qsize 7, out_qsize 0\n",
      "2018-06-07 14:39:41,678 : INFO : PROGRESS: at 60.08% examples, 237192 words/s, in_qsize 7, out_qsize 0\n",
      "2018-06-07 14:39:42,739 : INFO : PROGRESS: at 60.94% examples, 234846 words/s, in_qsize 7, out_qsize 0\n",
      "2018-06-07 14:39:43,744 : INFO : PROGRESS: at 61.66% examples, 233129 words/s, in_qsize 7, out_qsize 0\n",
      "2018-06-07 14:39:44,767 : INFO : PROGRESS: at 62.44% examples, 232582 words/s, in_qsize 7, out_qsize 0\n",
      "2018-06-07 14:39:45,773 : INFO : PROGRESS: at 63.30% examples, 231726 words/s, in_qsize 8, out_qsize 0\n",
      "2018-06-07 14:39:46,850 : INFO : PROGRESS: at 64.38% examples, 231610 words/s, in_qsize 7, out_qsize 1\n",
      "2018-06-07 14:39:47,907 : INFO : PROGRESS: at 65.14% examples, 230912 words/s, in_qsize 7, out_qsize 0\n",
      "2018-06-07 14:39:48,920 : INFO : PROGRESS: at 66.23% examples, 230253 words/s, in_qsize 8, out_qsize 0\n",
      "2018-06-07 14:39:49,947 : INFO : PROGRESS: at 66.68% examples, 228873 words/s, in_qsize 7, out_qsize 0\n",
      "2018-06-07 14:39:51,031 : INFO : PROGRESS: at 67.58% examples, 228288 words/s, in_qsize 8, out_qsize 0\n",
      "2018-06-07 14:39:52,043 : INFO : PROGRESS: at 68.80% examples, 227820 words/s, in_qsize 8, out_qsize 0\n",
      "2018-06-07 14:39:53,133 : INFO : PROGRESS: at 69.88% examples, 227115 words/s, in_qsize 8, out_qsize 2\n",
      "2018-06-07 14:39:54,137 : INFO : PROGRESS: at 71.05% examples, 227671 words/s, in_qsize 7, out_qsize 0\n",
      "2018-06-07 14:39:55,160 : INFO : PROGRESS: at 72.28% examples, 228152 words/s, in_qsize 7, out_qsize 0\n",
      "2018-06-07 14:39:56,221 : INFO : PROGRESS: at 73.71% examples, 228550 words/s, in_qsize 7, out_qsize 0\n",
      "2018-06-07 14:39:57,239 : INFO : PROGRESS: at 74.90% examples, 228821 words/s, in_qsize 8, out_qsize 0\n",
      "2018-06-07 14:39:58,273 : INFO : PROGRESS: at 76.16% examples, 229254 words/s, in_qsize 7, out_qsize 0\n",
      "2018-06-07 14:39:59,287 : INFO : PROGRESS: at 77.56% examples, 229783 words/s, in_qsize 8, out_qsize 0\n",
      "2018-06-07 14:40:00,300 : INFO : PROGRESS: at 78.68% examples, 230127 words/s, in_qsize 7, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-06-07 14:40:01,354 : INFO : PROGRESS: at 80.35% examples, 230686 words/s, in_qsize 7, out_qsize 0\n",
      "2018-06-07 14:40:02,354 : INFO : PROGRESS: at 81.90% examples, 231419 words/s, in_qsize 8, out_qsize 0\n",
      "2018-06-07 14:40:03,368 : INFO : PROGRESS: at 82.97% examples, 231873 words/s, in_qsize 7, out_qsize 1\n",
      "2018-06-07 14:40:04,438 : INFO : PROGRESS: at 84.22% examples, 232297 words/s, in_qsize 7, out_qsize 0\n",
      "2018-06-07 14:40:05,455 : INFO : PROGRESS: at 85.50% examples, 232801 words/s, in_qsize 8, out_qsize 0\n",
      "2018-06-07 14:40:06,457 : INFO : PROGRESS: at 86.59% examples, 233277 words/s, in_qsize 7, out_qsize 0\n",
      "2018-06-07 14:40:07,474 : INFO : PROGRESS: at 87.73% examples, 233797 words/s, in_qsize 8, out_qsize 0\n",
      "2018-06-07 14:40:08,501 : INFO : PROGRESS: at 89.26% examples, 234066 words/s, in_qsize 7, out_qsize 0\n",
      "2018-06-07 14:40:09,534 : INFO : PROGRESS: at 90.56% examples, 234437 words/s, in_qsize 8, out_qsize 0\n",
      "2018-06-07 14:40:10,558 : INFO : PROGRESS: at 91.70% examples, 234811 words/s, in_qsize 7, out_qsize 0\n",
      "2018-06-07 14:40:11,589 : INFO : PROGRESS: at 93.13% examples, 235110 words/s, in_qsize 7, out_qsize 0\n",
      "2018-06-07 14:40:12,611 : INFO : PROGRESS: at 94.48% examples, 235288 words/s, in_qsize 7, out_qsize 0\n",
      "2018-06-07 14:40:13,635 : INFO : PROGRESS: at 95.54% examples, 235398 words/s, in_qsize 7, out_qsize 0\n",
      "2018-06-07 14:40:14,661 : INFO : PROGRESS: at 96.64% examples, 235379 words/s, in_qsize 6, out_qsize 1\n",
      "2018-06-07 14:40:15,665 : INFO : PROGRESS: at 98.01% examples, 235455 words/s, in_qsize 8, out_qsize 0\n",
      "2018-06-07 14:40:16,691 : INFO : PROGRESS: at 99.05% examples, 235703 words/s, in_qsize 8, out_qsize 0\n",
      "2018-06-07 14:40:17,305 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-06-07 14:40:17,319 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-06-07 14:40:17,353 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-06-07 14:40:17,421 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-06-07 14:40:17,426 : INFO : training on 22780995 raw words (20806479 effective words) took 88.4s, 235292 effective words/s\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import word2vec\n",
    "print(\"Training model...\")\n",
    "model = word2vec.Word2Vec(sentences, workers=num_workers, \\\n",
    "            size=num_features, min_count = min_word_count, \\\n",
    "            window = context, sample = downsampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-06-07 14:40:47,906 : INFO : precomputing L2-norms of word weight vectors\n",
      "2018-06-07 14:40:48,237 : INFO : saving Word2Vec object under 300features_10minwords_10context, separately None\n",
      "2018-06-07 14:40:48,241 : INFO : not storing attribute syn0norm\n",
      "2018-06-07 14:40:48,245 : INFO : not storing attribute cum_table\n",
      "2018-06-07 14:40:48,982 : INFO : saved 300features_10minwords_10context\n"
     ]
    }
   ],
   "source": [
    "model.init_sims(replace=True)\n",
    "model_name = \"300features_10minwords_10context\"\n",
    "model.save(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tests', 0.6439777612686157),\n",
       " ('testcase', 0.5448951125144958),\n",
       " ('iteration', 0.5378092527389526),\n",
       " ('idart', 0.500475287437439),\n",
       " ('iterations', 0.4950413703918457),\n",
       " ('powerfails', 0.4846037030220032),\n",
       " ('tradi', 0.4772912263870239),\n",
       " ('seed', 0.4751446843147278),\n",
       " ('ddfailddsexcpio', 0.4699980318546295),\n",
       " ('injections', 0.458285927772522)]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
